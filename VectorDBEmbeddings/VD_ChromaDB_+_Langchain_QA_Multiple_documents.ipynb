{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Langchain + ChromaDB -Q&A Multiple files\n",
    "\n",
    "1. Multiple files\n",
    "2. ChromaDB\n",
    "3. gpt\n"
   ],
   "id": "df9f6c1d6957824a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sympy.physics.units import temperature\n",
    "from tenacity import wait_chain\n",
    "!pip -q install chromadb langchain langchain-community openai tiktoken"
   ],
   "id": "c251a28a6a656b3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip show langchain",
   "id": "80a892704280ea13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:05:26.201632Z",
     "start_time": "2025-12-04T16:05:22.026090Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain-openai",
   "id": "3b2bad5e25024166",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\r\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in ./.venv/lib/python3.9/site-packages (from langchain-openai) (0.3.80)\r\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in ./.venv/lib/python3.9/site-packages (from langchain-openai) (2.8.1)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.9/site-packages (from langchain-openai) (0.12.0)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.4.37)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (9.1.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (1.33)\r\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (6.0.3)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (4.15.0)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (25.0)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (2.12.5)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.12.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.9/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.9/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.9/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain-openai) (3.11)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (2025.11.12)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain-openai) (3.0.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (3.11.4)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.9/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.9/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.25.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.4.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\r\n",
      "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\r\n",
      "Installing collected packages: langchain-openai\r\n",
      "Successfully installed langchain-openai-0.3.35\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import os",
   "id": "54059cfe66db8f85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.environ['OPENAI_API_KEY'] = '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'",
   "id": "3c99c780e0c0b05f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:07:41.348281Z",
     "start_time": "2025-12-04T16:07:41.290474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma"
   ],
   "id": "a234d46b4643d0ec",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!unzip -q techcrunch_articles.zip -d articles",
   "id": "4066036c34cdf3df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load multiple documents and process documents\n",
    "\n",
    "loader = DirectoryLoader(\"./articles\", glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()"
   ],
   "id": "be45c107306938cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "documents",
   "id": "843a09adcd1654c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ],
   "id": "7de60b7f530679b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "texts",
   "id": "f29b1b3612adde3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(texts)",
   "id": "8da5aa995ee26f3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a ChromaDB\n",
    "persist_directory = \"db\"\n",
    "embedding = OpenAIEmbeddings()"
   ],
   "id": "253363d67ac3241b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents = texts,\n",
    "    embedding = embedding,\n",
    "    persist_directory = persist_directory,\n",
    ")"
   ],
   "id": "2a2843d0949cce39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# persist the db to the disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ],
   "id": "cc16006f7ee8538f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T13:13:35.234393Z",
     "start_time": "2025-12-03T13:13:35.222395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ],
   "id": "a5180222c99bfce6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/zgbvh5cd7bzbh1gc2w43v50r0000gn/T/ipykernel_92631/1946243145.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "972683f3c0b5c2d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:03:15.137902Z",
     "start_time": "2025-12-04T13:03:15.130666Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vectordb.as_retriever()",
   "id": "a4a0863269c0ced2",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:04:08.513424Z",
     "start_time": "2025-12-04T13:04:08.509348Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})",
   "id": "7ee2cf9d8ad04d8d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:04:25.309394Z",
     "start_time": "2025-12-04T13:04:25.305597Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.search_type",
   "id": "556429585fd53b02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T13:06:37.991911Z",
     "start_time": "2025-12-04T13:06:37.988855Z"
    }
   },
   "cell_type": "code",
   "source": "retriever.search_kwargs",
   "id": "d5e4e4ac9ace04c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:07:52.975538Z",
     "start_time": "2025-12-04T16:07:52.962397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#turbo_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 4. Create LLM with new ChatOpenAI (instead of old OpenAI())\n",
    "llm = ChatOpenAI( model=\"gpt-4.1-mini\",temperature=0)"
   ],
   "id": "60d3c70cd00bf66f",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:08:11.183089Z",
     "start_time": "2025-12-04T16:08:11.180646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")"
   ],
   "id": "c63b20b8198a0e8d",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:08:30.607132Z",
     "start_time": "2025-12-04T16:08:15.366435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the news about Pando?\"\n",
    "llm_response = qa_chain(query)"
   ],
   "id": "c62257eabca28ec6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:10:41.344157Z",
     "start_time": "2025-12-04T16:10:41.341087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response[\"result\"])\n",
    "    print(\"\\n\\nSources:\")\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ],
   "id": "8725139f6046801b",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:10:59.948953Z",
     "start_time": "2025-12-04T16:10:59.946151Z"
    }
   },
   "cell_type": "code",
   "source": "process_llm_response(llm_response=llm_response)",
   "id": "e0352105907819d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news about Pando is that the startup, which develops fulfillment management technologies for global logistics, has raised $30 million in a Series B funding round. This brings Pando's total funding to $45 million. The round was led by Iron Pillar and Uncorrelated Ventures, with participation from existing investors Nexus Venture Partners, Chiratae Ventures, and Next47. Pando plans to use the new capital to expand its global sales, marketing, and delivery capabilities, while continuing to focus on its core logistics software-as-a-service platform without expanding into new industries or product areas. The company is also open to exploring strategic partnerships and acquisitions with this funding.\n",
      "\n",
      "\n",
      "Sources:\n",
      "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:12:15.259033Z",
     "start_time": "2025-12-04T16:12:10.301840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what is the news about databrick?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response=llm_response)"
   ],
   "id": "8780b9c5046f6897",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news is that Databricks has acquired Okera, a company specializing in secure, scalable, and simple data governance solutions. This acquisition aims to enhance Databricks' ability to manage access policies across multiple clouds more efficiently, especially given the growing volume and complexity of data and the rise of large language models (LLMs). Okera's isolation technology, which can enforce governance controls on various workloads without significant overhead, was a key factor in the acquisition. Databricks plans to integrate Okera's technology into its Unity Catalog, its existing governance solution for data and AI assets, and will also expose additional APIs to enable its data governance partners to offer improved solutions to their customers.\n",
      "\n",
      "\n",
      "Sources:\n",
      "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
